[2025-12-04 15:09] DeepSeek OCR Integration Research & Architecture Planning
File: devlog/2512041509.txt

== What we worked on ==
- Evaluated whether to migrate HelloMimir backend from TypeScript/Next.js to Python for AI features
- Conducted exhaustive codebase analysis (2,522 lines across 883 total lines of business logic)
- Researched DeepSeek OCR capabilities and API integration options
- Designed comprehensive architecture for full-paper PDF processing
- Planned enhanced features: pre-reading materials, jargon definitions, prerequisites

== Changes made ==
- No code changes in this session (research & planning only)
- Created detailed implementation roadmap and cost analysis
- Documented three API integration options (Clarifai, Replicate, self-hosted vLLM)

== Problems encountered ==
- Problem 1: User wanted to migrate to Python for DeepSeek OCR access
  - Concern: Believed Python was required for advanced AI features
  - Risk: 3-4 weeks of migration work, loss of TypeScript safety, regression risks

- Problem 2: Current summaries only use paper abstracts, not full content
  - Limitation: Abstracts are 150-300 words, missing methodology/results/discussion
  - User need: Richer summaries and pre-reading guidance (jargon, prerequisites)

== How we tried to solve it ==
- Attempt 1: Comprehensive codebase review
  - Used Task tool with Explore subagent for deep codebase analysis
  - Read key files: dailyPaperService.ts (172 lines), llmClient.ts (194 lines),
    supabaseClient.ts (358 lines), arxivClient.ts (159 lines)
  - Analyzed business logic distribution and AI integration patterns

- Attempt 2: DeepSeek OCR research
  - WebSearch for DeepSeek OCR capabilities, pricing, API endpoints
  - WebFetch on DeepSeek API documentation
  - Found: DeepSeek-OCR is a 3B parameter vision-language model
  - Key finding: API-based, works from any language (HTTP/REST)

== How we solved it / Current status ==
- Solution for Problem 1: DO NOT MIGRATE TO PYTHON
  - Root cause: Misconception that Python is required for AI APIs
  - Key insight: DeepSeek OCR exposes HTTP APIs consumable from Node.js/TypeScript
  - All modern AI services (OpenAI, DeepSeek, etc.) are language-agnostic
  - Current OpenAI integration (llmClient.ts) proves TypeScript works perfectly
  - Trade-off: Would only need Python for custom ML model training (not planned)

- Solution for Problem 2: Designed full-paper processing pipeline
  - Architecture: arXiv PDF → DeepSeek OCR → Markdown → OpenAI/DeepSeek LLM → Enhanced content
  - New database tables planned:
    * ALTER papers ADD COLUMN full_text TEXT
    * CREATE TABLE paper_prereading (jargon_json, prerequisites_json, difficulty_level, etc.)
  - New TypeScript types: PaperPrereading, JargonEntry, PrerequisiteEntry
  - Three API integration options evaluated:
    * Option A (Recommended MVP): Clarifai API - OpenAI-compatible, $0.01-0.15/paper
    * Option B: Replicate API - Simple REST, async polling required
    * Option C: Self-hosted vLLM - Free after infrastructure, requires GPU (A100/H100)

== Key findings ==
- DeepSeek OCR capabilities:
  * 3B parameter vision-language model
  * Trained on 30M PDF pages, 100 languages
  * Handles math formulas, tables, diagrams, multi-column layouts
  * Outputs markdown format preserving structure
  * 97% accuracy at <10x compression
  * Processes 200k+ pages/day on single A100 GPU

- Cost analysis (per paper):
  * Current (abstract-only): $0.0015-0.003/paper via GPT-4o-mini
  * Proposed (full-paper, Clarifai): $0.04-0.18/paper (13-60x increase)
  * Monthly: $6-27/month for 5 fields daily (vs current $0.50-1.50)
  * Cost reduction path: Self-host OCR + DeepSeek-V3.2 LLM → $0.003/paper (~$0.45/month)

- Processing time impact:
  * Current: ~25-35 seconds per paper
  * Proposed: ~60-120 seconds per paper (2-3x longer)
  * Bottleneck: PDF OCR extraction (20-60s for 10-30 page papers)

== Architecture decisions ==
- Database schema updates:
  * papers.full_text (TEXT, nullable for backward compatibility)
  * paper_prereading table (jargon, prerequisites, difficulty, key_concepts, read_time)
  * Indexes on paper_prereading(paper_id, field_id)

- New service functions:
  * deepseekClient.extractFullPaperText(pdfUrl) → {fullText, pageCount}
  * llmClient.generatePrereading(title, abstract, fullText, field) → PaperPrereading
  * Enhanced generateSummary() and generateQuiz() to accept fullText parameter
  * supabaseClient CRUD operations for prereading table

- Frontend components:
  * <PreReadingGuide> component - displays jargon, prerequisites, difficulty, concepts
  * Update <PaperView> to include prereading section before summaries
  * Update API routes to fetch and return prereading data

== Recommended approach ==
- MVP Strategy (Phase 1): Pre-reading materials only
  * Use Clarifai API for DeepSeek OCR (fastest to implement, 1-2 days)
  * Generate pre-reading materials (highest user value)
  * Keep summaries/quizzes using abstracts initially (lower cost, faster ship)
  * Cost: ~$0.01-0.02/paper (~$3-6/month)
  * Implementation time: 1-2 weeks

- Phase 2 (if MVP successful):
  * Enhance summaries to use full text
  * Enhance quizzes to use full text
  * Add more sophisticated pre-reading features

- Phase 3 (if costs too high):
  * Self-host DeepSeek OCR with vLLM
  * Switch to DeepSeek-V3.2 for LLM calls (10x cheaper than GPT-4o-mini)
  * Target cost: ~$0.003/paper (~$0.45/month)

== Next steps / TODOs ==
1. [ ] Get user approval on MVP approach and budget
2. [ ] Decision: Choose API provider (Clarifai recommended for MVP)
3. [ ] Setup: Create Clarifai account, obtain API key
4. [ ] Code: Create database migration (002_add_full_text_and_prereading.sql)
5. [ ] Code: Update TypeScript types in src/types/index.ts
6. [ ] Code: Implement src/lib/deepseekClient.ts with OCR extraction
7. [ ] Test: Extract 3-5 sample papers, validate markdown quality
8. [ ] Code: Implement generatePrereading() in src/lib/llmClient.ts
9. [ ] Code: Add database operations in src/lib/supabaseClient.ts
10. [ ] Code: Update processDailyPaperForField() flow in src/lib/dailyPaperService.ts
11. [ ] Frontend: Create src/components/PreReadingGuide.tsx
12. [ ] Frontend: Update src/components/PaperView.tsx to display prereading
13. [ ] Frontend: Update API route src/app/api/field/[slug]/today/route.ts
14. [ ] Test: End-to-end with 10-20 real papers across all fields
15. [ ] Deploy: Ship MVP and gather user feedback
16. [ ] Monitor: Track costs, processing time, and user engagement

== Success metrics ==
- OCR extraction success rate >95%
- Pre-reading materials rated helpful by users
- Processing time <2 minutes per paper
- Monthly costs <$10 for MVP phase
- User engagement with pre-reading section (analytics)

== Technical references ==
- DeepSeek OCR GitHub: https://github.com/deepseek-ai/DeepSeek-OCR
- DeepSeek OCR HuggingFace: https://huggingface.co/deepseek-ai/DeepSeek-OCR
- DeepSeek API Docs: https://api-docs.deepseek.com/
- Clarifai DeepSeek OCR: https://www.clarifai.com/blog/run-deepseek-ocr-with-an-api
- vLLM DeepSeek OCR Recipe: https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html

== Current codebase stats ==
- Total application code: 2,522 lines TypeScript/TSX
- Business logic: 683 lines (27%)
- Data access layer: 358 lines (14%)
- Frontend/UI: 700+ lines (28%)
- API routes: 295 lines (12%)
- Database schema: 5 tables, 6 indexes
- Current AI integration: OpenAI GPT-4o-mini for summaries + quizzes
- No test coverage (risk for future refactoring)

== Files analyzed ==
- src/lib/dailyPaperService.ts (172 lines) - Core orchestration
- src/lib/llmClient.ts (194 lines) - OpenAI integration
- src/lib/arxivClient.ts (159 lines) - Paper discovery
- src/lib/supabaseClient.ts (358 lines) - Database operations
- src/types/index.ts (98 lines) - Type definitions
- src/components/PaperView.tsx (180 lines) - Main paper display
- src/components/Quiz.tsx (359 lines) - Interactive quizzes
- supabase/migrations/001_initial_schema.sql (76 lines) - DB schema
- src/app/api/cron/daily-papers/route.ts (107 lines) - Scheduled job
- package.json - Dependencies and config

== Risk mitigation strategies ==
- Risk 1: OCR quality issues with complex equations/diagrams
  * Mitigation: Fallback to abstract-only, confidence scoring, manual review

- Risk 2: Token limits exceeded (papers >50k tokens)
  * Mitigation: Truncate to first 30k tokens, chunk-and-summarize, section selection

- Risk 3: Processing time too long (>2 min per paper)
  * Mitigation: Earlier cron jobs (2am vs 6am), async processing, cross-field caching

- Risk 4: Costs spiral out of control
  * Mitigation: Daily cost monitoring, self-hosting fallback, rate limiting

== Session outcome ==
✅ Confirmed: No Python migration needed - TypeScript works perfectly for AI APIs
✅ Designed: Complete architecture for full-paper processing with DeepSeek OCR
✅ Validated: Three viable API integration paths (Clarifai, Replicate, self-hosted)
✅ Planned: MVP approach focusing on high-value pre-reading materials
✅ Estimated: Costs ($3-27/month), timeline (1-2 weeks MVP), and success metrics
✅ Ready: Clear next steps and implementation roadmap

User is ready to proceed with implementation when approved.
